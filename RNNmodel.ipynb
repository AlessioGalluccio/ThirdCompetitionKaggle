{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"img_h = 224\nimg_w = 224\nh_size = 128\nseq_length = 100\nvocabulary= 500\nnum_classes = 13\nnum_first_LSTM_layers = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\n\n# Set the seed for random operations. \n# This let our experiments to be reproducible. \nSEED = 12\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\n# Get current working directory\ncwd = os.getcwd()\n\n# Set GPU memory growth\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport keras\nfrom keras.preprocessing.image import load_img, img_to_array\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, path, json_dict, batch_size=32, dim=(img_h, img_w), n_channels=3,\n                 n_classes=13, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.path = path\n        self.questions = json_dict['questions']\n        self.n_questions = len(self.questions)\n        self.list_IDs = self.__generate_IDs()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X_image, X_question, y = self.__data_generation(list_IDs_temp)\n\n        return X_image, X_question, y\n    \n    def __generate_IDs(self):\n        'Generate question IDs'\n        list_IDs = np.arange(self.n_questions)\n        return list_IDs.tolist()\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        size = min(self.batch_size, len(list_IDs_temp))\n        X_image = np.empty((size, *self.dim, self.n_channels))\n        X_question = []\n\n        y = np.empty((size), dtype=int)\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            image_filename = self.questions[ID]['image_filename']\n            image_path = self.path + image_filename\n            PIL_image = load_img(image_path)\n            #resize the image to (224,224)\n            PIL_image = PIL_image.resize((img_h,img_w), Image.ANTIALIAS)\n            X_image[i,] = img_to_array(PIL_image)\n            \n            X_question.append(self.questions[ID]['question'])\n\n            # Store class\n            answer = self.questions[ID]['answer']\n            if answer == 'no':\n                y[i] = 11\n            elif answer == 'yes':\n                y[i] = 12\n            else:\n                y[i] = answer\n        \n#         print(set(y))\n\n        return X_image, X_question, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/ann-and-dl-vqa/dataset_vqa/train_data.json', 'r') as f:\n    json_dict = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dg = DataGenerator('/kaggle/input/ann-and-dl-vqa/dataset_vqa/train/', json_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dg.data_generation([1,2,3,4,5])\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_dict['questions'][1:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport time\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\nfrom PIL import Image\n\nfig, ax = plt.subplots(1, 5, figsize=(16,16))\nfor i in range(5):\n    img_arr = np.expand_dims(data[0][i], 0)\n    ax[i].imshow(np.uint8(img_arr[0, ...]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load VGG19\ntransfer = tf.keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_shape=(224, 224, 3), pooling='None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_input = tf.keras.layers.Input(shape=(224, 224, 3))\nx = transfer.get_layer(\"block1_conv1\")(image_input)\nx = transfer.get_layer(\"block1_conv2\")(x)\nx = transfer.get_layer(\"block1_pool\")(x)\nx = transfer.get_layer(\"block2_conv1\")(x)\nx = transfer.get_layer(\"block2_conv2\")(x)\nx = transfer.get_layer(\"block2_pool\")(x)\nx = transfer.get_layer(\"block3_conv1\")(x)\nx = transfer.get_layer(\"block3_conv2\")(x)\nx = transfer.get_layer(\"block3_conv3\")(x)\nx = transfer.get_layer(\"block3_conv4\")(x)\nx = transfer.get_layer(\"block3_pool\")(x)\nx = transfer.get_layer(\"block4_conv1\")(x)\nx = transfer.get_layer(\"block4_conv2\")(x)\nx = transfer.get_layer(\"block4_conv3\")(x)\nx = transfer.get_layer(\"block4_conv4\")(x)\nx = transfer.get_layer(\"block4_pool\")(x)\nx = transfer.get_layer(\"block5_conv1\")(x)\nx = transfer.get_layer(\"block5_conv2\")(x)\nx = transfer.get_layer(\"block5_conv3\")(x)\nx = transfer.get_layer(\"block5_conv4\")(x)\nx = transfer.get_layer(\"block5_pool\")(x)\nx = transfer.get_layer(\"flatten\")(x)\nx = transfer.get_layer(\"fc1\")(x)\nimage_output = transfer.get_layer(\"fc2\")(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transfer.trainable = False\n#image_model = tf.keras.Sequential()\n#image_model.add(transfer)\n#image_model.add(tf.keras.layers.Flatten())\n#image_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#language_model = tf.keras.Sequential()\n##################################################################################################################\n#QUETSA SOTTO E' CORRETTA, MA SERVE VOCABULARY\n#model.add(tf.keras.layers.LSTM(units=h_size, batch_input_shape=[None, seq_length, len(vocabulary)], \n #                              return_sequences=True, stateful=False))\n#QUESTA SOTTO NON E' CORRETTA, MA E' TESTABILE\n#for i in range(num_first_LSTM_layers):\n # language_model.add(tf.keras.layers.LSTM(units=h_size, batch_input_shape=[None, seq_length, 1000], \n                               return_sequences=True, stateful=False))\n###############################################################################################################\n#language_model.add(tf.keras.layers.LSTM(units=h_size, return_sequences=False, stateful=False))\n#language_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_input = tf.keras.layers.Input(shape=(h_size,), dtype='int32')\nembedded_question = tf.keras.layers.Embedding(input_dim=10000, output_dim=256, input_length=h_size)(question_input)\nlanguage_output = tf.keras.layers.LSTM(256)(embedded_question)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = tf.keras.layers.concatenate([image_output, language_output])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dense_1 = tf.keras.layers.Dense(units = 128, activation='softmax')(combined)\noutput = tf.keras.layers.Dense(units = num_classes, activation='softmax')(dense_1)\nmodel = tf.keras.models.Model(inputs=[image_input, question_input], outputs=output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}